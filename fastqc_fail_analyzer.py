#!/usr/bin/env python3
"""
FastQC FAILçŠ¶æ€è¯¦ç»†åˆ†æå™¨
ä¸“é—¨è§£æalt="[FAIL]"çš„è´¨æ§é—®é¢˜
"""

import re
from pathlib import Path

def parse_fastqc_fail_status(html_file):
    """è§£æFastQCæŠ¥å‘Šä¸­çš„FAILçŠ¶æ€"""
    print(f"\n=== è¯¦ç»†è§£æFAILçŠ¶æ€: {html_file.name} ===")
    
    with open(html_file, 'r', encoding='utf-8', errors='ignore') as f:
        content = f.read()
    
    # æŸ¥æ‰¾æ‰€æœ‰FAILçŠ¶æ€çš„å›¾ç‰‡æ ‡è®°
    fail_patterns = [
        r'alt="\[FAIL\]"',  # æ ‡å‡†FAILæ ‡è®°
        r'alt="FAIL"',      # å¯èƒ½çš„å˜ä½“
        r'class="FAIL"',    # FAILç±»
        r'>FAIL</',         # FAILæ–‡æœ¬
    ]
    
    fail_matches = []
    for pattern in fail_patterns:
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            fail_matches.extend(matches)
    
    # æŸ¥æ‰¾FAILå¯¹åº”çš„æ¨¡å—åç§°
    fail_modules = []
    
    # æŸ¥æ‰¾æ¨¡å—åç§°çš„æ¨¡å¼
    module_patterns = [
        r'alt="\[FAIL\]"[^>]*>\s*([^<]+)</td>',
        r'class="FAIL">([^<]+)</td>',
        r'>FAIL</td>\s*<td[^>]*>([^<]+)</td>',
    ]
    
    for pattern in module_patterns:
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            fail_modules.extend([m.strip() for m in matches if len(m.strip()) > 5])
    
    # å¦‚æœç›´æ¥æŸ¥æ‰¾å¤±è´¥ï¼Œå°è¯•æŸ¥æ‰¾FAILé™„è¿‘çš„æ¨¡å—åç§°
    if not fail_modules and fail_matches:
        # æŸ¥æ‰¾FAILæ ‡è®°å‰åçš„æ–‡æœ¬å†…å®¹
        context_pattern = r'([^>]{0,100})alt="\[FAIL\]"([^<]{0,100})'
        context_matches = re.findall(context_pattern, content, re.IGNORECASE)
        
        for before, after in context_matches:
            # ä»å‰åæ–‡æœ¬ä¸­æå–å¯èƒ½çš„æ¨¡å—åç§°
            module_candidates = re.findall(r'>([^<>]{10,50})</', before + after)
            for candidate in module_candidates:
                if len(candidate.strip()) > 5 and 'FAIL' not in candidate.upper():
                    fail_modules.append(candidate.strip())
    
    # å»é‡
    fail_modules = list(set(fail_modules))
    
    print(f"å‘ç°FAILæ ‡è®°: {len(fail_matches)} ä¸ª")
    print(f"è¯†åˆ«FAILæ¨¡å—: {len(fail_modules)} ä¸ª")
    
    if fail_modules:
        print("å…·ä½“FAILæ¨¡å—:")
        for module in fail_modules:
            print(f"  âŒ {module}")
    
    return fail_modules

def analyze_fail_reasons(fail_modules, html_file):
    """åˆ†æFAILåŸå› å¹¶æä¾›è§£å†³æ–¹æ¡ˆ"""
    print(f"\n=== FAILåŸå› åˆ†æ ===")
    
    # è¯»å–æ–‡ä»¶å†…å®¹è¿›è¡Œè¯¦ç»†åˆ†æ
    with open(html_file, 'r', encoding='utf-8', errors='ignore') as f:
        content = f.read()
    
    fail_analysis = {}
    
    for module in fail_modules:
        module_lower = module.lower()
        
        # æ ¹æ®æ¨¡å—åç§°åˆ†æå¯èƒ½çš„åŸå› 
        if 'per base sequence quality' in module_lower:
            fail_analysis[module] = {
                'reason': 'ç¢±åŸºè´¨é‡åˆ†æ•°è¿‡ä½æˆ–è´¨é‡ä¸‹é™',
                'severity': 'é«˜',
                'impact': 'å½±å“æ¯”å¯¹å‡†ç¡®æ€§å’ŒåŸºå› å®šé‡',
                'solution': 'ä½¿ç”¨trim_galoreè¿›è¡Œè´¨é‡ä¿®å‰ªï¼Œè®¾ç½®--quality 20',
                'parameters': '--quality 20 --length 50'
            }
        
        elif 'per sequence quality scores' in module_lower:
            fail_analysis[module] = {
                'reason': 'åºåˆ—è´¨é‡åˆ†å¸ƒå¼‚å¸¸',
                'severity': 'ä¸­',
                'impact': 'å¯èƒ½å½±å“æŸäº›åˆ†æå·¥å…·',
                'solution': 'æ£€æŸ¥æµ‹åºå¹³å°å’Œæ–‡åº“æ„å»ºè´¨é‡',
                'parameters': 'å»ºè®®é‡æ–°æµ‹åºæˆ–ä½¿ç”¨è´¨é‡æ§åˆ¶å·¥å…·'
            }
        
        elif 'per base sequence content' in module_lower:
            fail_analysis[module] = {
                'reason': 'ç¢±åŸºç»„æˆå­˜åœ¨ç³»ç»Ÿæ€§åå·®',
                'severity': 'ä¸­',
                'impact': 'å¯èƒ½å½±å“æŸäº›åˆ†æä½†é€šå¸¸å¯æ¥å—',
                'solution': 'å¯èƒ½æ˜¯æµ‹åºèµ·å§‹åå·®ï¼Œé€šå¸¸å¯å¿½ç•¥',
                'parameters': '--clip_R1 10 --clip_R2 10 (å»é™¤å‰10bp)'
            }
        
        elif 'adapter content' in module_lower:
            fail_analysis[module] = {
                'reason': 'æ£€æµ‹åˆ°æ¥å¤´åºåˆ—æ±¡æŸ“',
                'severity': 'é«˜',
                'impact': 'ä¸¥é‡å½±å“æ¯”å¯¹å’Œå®šé‡å‡†ç¡®æ€§',
                'solution': 'å¿…é¡»å»é™¤æ¥å¤´åºåˆ—',
                'parameters': '--adapter AGATCGGAAGAGC (Illuminaé€šç”¨æ¥å¤´)'
            }
        
        elif 'overrepresented sequences' in module_lower:
            fail_analysis[module] = {
                'reason': 'å­˜åœ¨è¿‡è¡¨è¾¾åºåˆ—',
                'severity': 'ä¸­',
                'impact': 'å¯èƒ½è¡¨ç¤ºæ±¡æŸ“æˆ–æŠ€æœ¯é—®é¢˜',
                'solution': 'æ£€æŸ¥æ˜¯å¦ä¸ºrRNAæ±¡æŸ“æˆ–æŠ€æœ¯é‡å¤',
                'parameters': 'ä½¿ç”¨kraken2è¿›è¡Œç‰©ç§é‰´å®š'
            }
        
        elif 'per tile sequence quality' in module_lower:
            fail_analysis[module] = {
                'reason': 'æµ‹åºèŠ¯ç‰‡è´¨é‡ä¸å‡',
                'severity': 'ä½',
                'impact': 'é€šå¸¸ä¸å½±å“ä¸‹æ¸¸åˆ†æ',
                'solution': 'æµ‹åºä»ªé—®é¢˜ï¼Œé€šå¸¸å¯æ¥å—',
                'parameters': 'æ— éœ€ç‰¹æ®Šå¤„ç†'
            }
        
        elif 'sequence length distribution' in module_lower:
            fail_analysis[module] = {
                'reason': 'åºåˆ—é•¿åº¦åˆ†å¸ƒå¼‚å¸¸',
                'severity': 'ä¸­',
                'impact': 'å¯èƒ½å½±å“æŸäº›åˆ†æå·¥å…·',
                'solution': 'æ£€æŸ¥æ–‡åº“æ„å»ºå’Œæµ‹åºå‚æ•°',
                'parameters': 'è®¾ç½®åˆé€‚çš„é•¿åº¦è¿‡æ»¤é˜ˆå€¼'
            }
        
        else:
            # æœªçŸ¥æ¨¡å—çš„é€šç”¨åˆ†æ
            fail_analysis[module] = {
                'reason': 'æœªçŸ¥è´¨æ§é—®é¢˜',
                'severity': 'å¾…å®š',
                'impact': 'éœ€è¦è¿›ä¸€æ­¥åˆ†æ',
                'solution': 'æŸ¥çœ‹è¯¦ç»†FastQCæŠ¥å‘Š',
                'parameters': 'éœ€è¦äººå·¥æ£€æŸ¥'
            }
    
    return fail_analysis

def generate_fail_optimization_plan(all_fail_analysis):
    """ç”ŸæˆFAILä¼˜åŒ–æ–¹æ¡ˆ"""
    print(f"\n=== è´¨æ§FAILä¼˜åŒ–æ–¹æ¡ˆ ===")
    
    if not all_fail_analysis:
        print("âœ“ æœªå‘ç°FAILæ¨¡å—ï¼Œæ•°æ®è´¨é‡è‰¯å¥½")
        return
    
    # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»
    high_severity = {}
    medium_severity = {}
    low_severity = {}
    
    for sample, analysis in all_fail_analysis.items():
        for module, info in analysis.items():
            if info['severity'] == 'é«˜':
                high_severity[f"{sample}: {module}"] = info
            elif info['severity'] == 'ä¸­':
                medium_severity[f"{sample}: {module}"] = info
            else:
                low_severity[f"{sample}: {module}"] = info
    
    # è¾“å‡ºä¼˜åŒ–å»ºè®®
    if high_severity:
        print(f"\nğŸ”´ é«˜ä¸¥é‡æ€§é—®é¢˜ ({len(high_severity)} ä¸ª):")
        for module_key, info in high_severity.items():
            print(f"\nâŒ {module_key}")
            print(f"   åŸå› : {info['reason']}")
            print(f"   å½±å“: {info['impact']}")
            print(f"   è§£å†³æ–¹æ¡ˆ: {info['solution']}")
            print(f"   å‚æ•°å»ºè®®: {info['parameters']}")
    
    if medium_severity:
        print(f"\nğŸŸ¡ ä¸­ç­‰ä¸¥é‡æ€§é—®é¢˜ ({len(medium_severity)} ä¸ª):")
        for module_key, info in medium_severity.items():
            print(f"\nâš ï¸  {module_key}")
            print(f"   åŸå› : {info['reason']}")
            print(f"   è§£å†³æ–¹æ¡ˆ: {info['solution']}")
    
    if low_severity:
        print(f"\nğŸŸ¢ ä½ä¸¥é‡æ€§é—®é¢˜ ({len(low_severity)} ä¸ª):")
        for module_key, info in low_severity.items():
            print(f"\nâ„¹ï¸  {module_key}")
            print(f"   åŸå› : {info['reason']}")
    
    # ç”Ÿæˆå…·ä½“çš„ä¼˜åŒ–æ­¥éª¤
    print(f"\n=== æ¨èä¼˜åŒ–æ­¥éª¤ ===")
    
    optimization_steps = []
    
    if any('adapter content' in key.lower() for key in high_severity.keys()):
        optimization_steps.append("1. å¿…é¡»è¿›è¡Œæ¥å¤´å»é™¤: trim_galore --adapter AGATCGGAAGAGC")
    
    if any('per base sequence quality' in key.lower() for key in high_severity.keys()):
        optimization_steps.append("2. è´¨é‡ä¿®å‰ª: trim_galore --quality 20 --length 50")
    
    if any('overrepresented sequences' in key.lower() for key in medium_severity.keys()):
        optimization_steps.append("3. æ£€æŸ¥è¿‡è¡¨è¾¾åºåˆ—: ä½¿ç”¨kraken2è¿›è¡Œæ±¡æŸ“æ£€æµ‹")
    
    if optimization_steps:
        for step in optimization_steps:
            print(f"  {step}")
    else:
        print("  æ— éœ€ç‰¹æ®Šä¼˜åŒ–æ­¥éª¤")

def main():
    """ä¸»åˆ†ææµç¨‹"""
    qc_dir = Path("analysis_results_1114/quality_control")
    
    if not qc_dir.exists():
        print(f"é”™è¯¯: è´¨æ§ç›®å½•ä¸å­˜åœ¨: {qc_dir}")
        return
    
    html_files = list(qc_dir.glob("*.html"))
    
    if not html_files:
        print("æœªæ‰¾åˆ°FastQC HTMLæŠ¥å‘Š")
        return
    
    all_fail_analysis = {}
    
    for html_file in html_files:
        fail_modules = parse_fastqc_fail_status(html_file)
        
        if fail_modules:
            fail_analysis = analyze_fail_reasons(fail_modules, html_file)
            all_fail_analysis[html_file.name] = fail_analysis
    
    generate_fail_optimization_plan(all_fail_analysis)
    
    print(f"\n=== åˆ†æå®Œæˆ ===")
    print("\nä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
    print("1. æ ¹æ®FAILåˆ†æç»“æœä¼˜åŒ–è´¨æ§æµç¨‹")
    print("2. å®æ–½æ¨èçš„ä¼˜åŒ–æ­¥éª¤")
    print("3. é‡æ–°è¿è¡Œè´¨æ§éªŒè¯æ”¹è¿›æ•ˆæœ")

if __name__ == "__main__":
    main()